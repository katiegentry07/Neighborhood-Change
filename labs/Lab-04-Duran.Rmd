---
title: 'Lab 4: Descriptive Analysis'
author: "Ricky Duran"
date: "`r format(Sys.time(), '%B %d, %Y')`"
highlight: github
theme: cayman
Output:
  prettydoc::html_pretty: null
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T, fig.width=10, fig.height=6, warning=F, message=F )

library( knitr )
library( stargazer )
library( scales )

library( geojsonio )   # read shapefiles
library( sp )          # work with shapefiles
library( sf )          # work with shapefiles - simple features format
library( mclust )      # cluster analysis 
library( tmap )        # theme maps
library( ggplot2 )     # graphing 
library( ggthemes )    # nice formats for ggplots
library( dplyr )       # data wrangling 
library( pander )      # formatting RMD tables
library( tidycensus )

library( cartogram )  # spatial maps w/ tract size bias reduction
library( maptools )   # spatial object manipulation 


s.type <- "text"  

```

```{r}
###################################
#
#     STARGAZER SETTINGS
#
###################################

# DO NOT RUN CHUNK UNLESS KNITTING:
# changes table formats to html
# before rendering RMD docs

s.type <- "html"
```

## Data

See the data steps for the wrangling that occurs during the process of creating our rodeo datasets.

```{r}
d1 <- readRDS( "C:/Users/rduran3/Dropbox (ASU)/MPP/CPP 528 - Data Sciences III/group1project/cpp-528-spr-2020-group-01/data/rodeo/LTDB-1990.rds" )
d2 <- readRDS( "C:/Users/rduran3/Dropbox (ASU)/MPP/CPP 528 - Data Sciences III/group1project/cpp-528-spr-2020-group-01/data/rodeo/LTDB-2000.rds" )
md <- readRDS( "C:/Users/rduran3/Dropbox (ASU)/MPP/CPP 528 - Data Sciences III/group1project/cpp-528-spr-2020-group-01/data/rodeo/LTDB-META-DATA.rds" )

# check to make sure we are not losing 
# or gaining observations in the merge
nrow( d1 ) 
```

```{r}
d1 <- select( d1, - year )
d2 <- select( d2, - year )

d <- merge( d1, d2, by="tractid" )
d <- merge( d, md, by="tractid" )

nrow( d )
```

## Filter Rural Districts

```{r}
table( d$urban )
```

```{r}
d <- filter( d, urban == "urban" )
```

## Identify Common Variables

We can create a function to compare variables from the 2000 and 2010 datasets:

```{r}
# find variables that are in both files
compare_dfs <- function( df1, df2 )
{
  # use regular expressions to remove numeric suffixes 
  var.names.1 <- names( df1 )
  var.names.1 <- gsub( "[.][xy]$", "", var.names.1 )
  var.names.1 <- gsub( "[0-9]{2}$", "", var.names.1 )
  
  var.names.2 <- names( df2 )
  var.names.2 <- gsub( "[.][xy]$", "", var.names.2 )
  var.names.2 <- gsub( "[0-9]{2}$", "", var.names.2 )
  
  shared <- intersect( var.names.1, var.names.2 ) %>% sort()
  print( "SHARED VARIABLES:")
  print( shared )
  
  not.shared <- c( setdiff( var.names.1, var.names.2 ),
                   setdiff( var.names.2, var.names.1 ) ) %>% sort()
  
  print( "NOT SHARED:" )
  print( not.shared )
  
  d.vars1 <- data.frame( type="shared", variables=shared, stringsAsFactors=F )
  d.vars2 <- data.frame( type="not shared", variables=not.shared, stringsAsFactors=F )
  dd <- rbind( d.vars1, d.vars2 )
  
  return( dd )
}

vars <- compare_dfs( df1=d1, df2=d2 )
```

```{r}
head( vars,100 )
```

## Create Dataset for Analysis

Create subset for the analysis

```{r}
d.full <- d  # keep a copy so don't have to reload 
```

```{r}
d <- d.full  # story original in case you need to reset anything

d <- select( d, tractid, mhmval90, mhmval00, hinc90, 
             hu90, own90, rent90,  
             empclf90, clf90, unemp90, prof90,  
             dpov90, npov90,
             ag25up90, hs90, col90, 
             pop90.1, nhwht90, nhblk90, hisp90, asian90,
             cbsa, cbsaname )
d <- 
  d %>%
  mutate( p.white = 100 * nhwht90 / pop90.1,
          p.black = 100 * nhblk90 / pop90.1,
          p.hisp = 100 * hisp90 / pop90.1, 
          p.asian = 100 * asian90 / pop90.1,
          p.hs = 100 * (hs90+col90) / ag25up90,
          p.col = 100 * col90 / ag25up90,
          p.prof = 100 * prof90 / empclf90,
          p.unemp = 100 * unemp90 / clf90,
          pov.rate = 100 * npov90 / dpov90 )
```

If you call the stargazer() function with a linear model object (a regression model) it will create a nicely-formatted regression table for you.

If you instead use a data frame object it will create a table of descriptive statistics.

You can set the statistics you would like reported in the table with the **summary.stat=** argument.

```{r}
stargazer( d, 
           type=s.type, 
           digits=0,
           summary.stat = c("min", "p25","median","mean","p75","max") )
```

## Exploration of Median Home Value

Initial conditions in 1990:

```{r}
# adjust 2000 home values for inflation 
mhv.90 <- d$mhmval90 * 1.28855  
mhv.00 <- d$mhmval00

mhv.change <- mhv.00 - mhv.90

df <- data.frame( MedianHomeValue1990=mhv.90, 
                  MedianHomeValue2000=mhv.00, 
                  Change.90.to.00=mhv.change )

stargazer( df, 
           type=s.type, 
           digits=0, 
           summary.stat = c("min", "p25","median","mean","p75","max") )
```

## Histogram of MHV

```{r}
hist( mhv.change/1000, breaks=500, 
      xlim=c(-100,500), yaxt="n", xaxt="n",
      xlab="Thousand of US Dollars (adjusted to 2000)", cex.lab=1.5,
      ylab="", main="Change in Median Home Value 1990 to 2000",
      col="gray20", border="white" )

axis( side=1, at=seq( from=-100, to=500, by=100 ), 
      labels=paste0( "$", seq( from=-100, to=500, by=100 ), "k" ) )
        
mean.x <- mean( mhv.change/1000, na.rm=T )
abline( v=mean.x, col="darkorange", lwd=2, lty=2 )
text( x=200, y=1500, 
      labels=paste0( "Mean = ", dollar( round(1000*mean.x,0)) ), 
      col="darkorange", cex=1.8, pos=3 )

median.x <- median( mhv.change/1000, na.rm=T )
abline( v=median.x, col="dodgerblue", lwd=2, lty=2 )
text( x=200, y=2000, 
      labels=paste0( "Median = ", dollar( round(1000*median.x,0)) ), 
      col="dodgerblue", cex=1.8, pos=3 )
```

```{r}
# function to control plot() formatting 
jplot <- function( x1, x2, lab1="", lab2="", draw.line=T, ... )
{

    plot( x1, x2,
          pch=19, 
          col=gray(0.6, alpha = 0.2), 
          cex=2.5,  
          bty = "n",
          xlab=lab1, 
          ylab=lab2, cex.lab=1.5,
        ... )

    if( draw.line==T ){ 
        ok <- is.finite(x1) & is.finite(x2)
        lines( lowess(x2[ok]~x1[ok]), col="red", lwd=3 ) }

}
```

Compare 1990 to 2000 distributions.

```{r}
layout.matrix <- matrix( c( 1,3,
                            2,3 ), 
                nrow=2, ncol=2, byrow=T )

layout( mat = layout.matrix,
        heights = c(2,2), # Heights of the two rows
        widths =  c(3,4)) # Widths of the two columns

# layout.show(3)

par( mar=c(4,0,0,2) )

hist( mhv.90/1000, breaks=50, 
      xlim=c(-200,800), yaxt="n", xaxt="n",
      xlab="", cex.lab=1,
      ylab="", main="",
      col="darkslateblue", border="white" )

axis( side=1, at=seq( from=0, to=1000, by=100 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=100 ), "k" ) )

abline( v=seq(0,1000,100), lty=2, col="gray80" )

text( 550, 4000, labels="Median Home \nValue in 1990", 
      col="darkslateblue", cex=1.8 )



hist( mhv.00/1000, breaks=50, 
      xlim=c(-200,800), yaxt="n", xaxt="n",
      xlab="", cex.lab=1,
      ylab="", main="",
      col="darkslateblue", border="white" )

abline( v=seq(0,1000, 100 ), lty=2, col="gray80" )

text( 550, 3500, labels="Median Home \nValue in 2000", 
      col="darkslateblue", cex=1.8 )

axis( side=1, at=seq( from=0, to=1000, by=100 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=100 ), "k" ) )


# data reduction - filter 1,000 observations

df <- data.frame( v90=mhv.90/1000, v00=mhv.00/1000 )
df <- sample_n( df, 1000 )

par( mar=c(4,5,3,2) )

jplot( df$v90, df$v00, 
       lab1="MHV in 1990", lab2="MHV in 2000",
       xlim=c(0,1000), ylim=c(0,1000),
       axes=F )

abline( a=0, b=1, lty=2, col="gray" )
axis( side=1, at=seq( from=0, to=1000, by=200 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=200 ), "k" ) )
axis( side=2, at=seq( from=0, to=1000, by=200 ), 
      labels=paste0( "$", seq( from=0, to=1000, by=200 ), "k" ) )

```

## Change in MHV 1990-2000

```{r}
# small initial values are skewing percentages
#
# an average home value below $10k is really low -
# these must be mostly vacant lots?

# interpretation is hard if there were no homes in 2000
# and thus an artificially low MHV. i don't trust cases
# that go from homes worth $10k to regular value
# because it is more likely errors in data or noise
# than meaningful variance 
#
# quick filter to remove all of the problematic obs
# but need to go back and see which cases are problematic


mhv.90[ mhv.90 < 1000 ] <- NA
pct.change <- mhv.change / mhv.90
summary( pct.change )
```

```{r}
# how many cases had increases above 500%
sum( pct.change > 5, na.rm=T )
```

```{r}
# preview tracts with large increases in home values 
# to see if increases make sense 

d %>% 
  filter( pct.change > 5 ) %>% 
  head() 

```

```{r}
hg <-
hist( pct.change, breaks=1990, 
      xlim=c(-1,2), yaxt="n", xaxt="n",
      xlab="", cex.main=1.5,
      ylab="", main="Growth in Home Value by Census Tract 1990 to 2000",
      col="gray40", border="white" )

axis( side=1, at=seq( from=-1, to=2, by=0.5 ), 
      labels=paste0( seq( from=-100, to=200, by=50 ), "%" ) )

ymax <- max( hg$count )
        
mean.x <- mean( pct.change, na.rm=T )
abline( v=mean.x, col="darkorange", lwd=2, lty=2 )
text( x=1, y=(0.5*ymax), 
      labels=paste0( "Mean = ", round(100*mean.x,0), "%"), 
      col="darkorange", cex=1.8, pos=4 )

median.x <- median( pct.change, na.rm=T )
abline( v=median.x, col="dodgerblue", lwd=2, lty=2 )
text( x=1, y=(0.6*ymax), 
      labels=paste0( "Median = ", round(100*median.x,0), "%"), 
      col="dodgerblue", cex=1.8, pos=4 )
```

## Group Growth Rates By Metro Area

We often want to disagregate descriptives by some grouping in the data, such as metro areas.

dplyr makes this easy by grouping then summarizing the data.

```{r}
d$mhv.change <- mhv.change 
d$pct.change <- pct.change
d$mhv.00 <- mhv.00
d$mhv.90 <- mhv.90

d %>%
  group_by( cbsaname ) %>%
  summarize( ave.change = median( mhv.change, na.rm=T ),
             ave.change.d = dollar( round(ave.change,0) ),
             growth = 100 * median( pct.change, na.rm=T ) ) %>%
  ungroup() %>%
  arrange( - growth ) %>%
  select( - ave.change ) %>% 
  head( 25 ) %>%
  pander()
```

## Measuring Gentrification

The original merged dataset we saved as d.full so we don’t need to reload it:

```{r}
d2 <- d.full
```

Recall our data steps thus far:

```{r}
# adjust 2000 home values for inflation 
mhv.90 <- d2$mhmval90 * 1.28855  
mhv.00 <- d2$mhmval00

mhv.change <- mhv.00 - mhv.90

# small initial values are skewing percentages
#
# an average home value below $10k is really low -
# these must be mostly vacant lots?

mhv.90[ mhv.90 < 1000 ] <- NA
pct.change <- 100 * ( mhv.change / mhv.90 )
summary( pct.change )
```

```{r}
d2$mhv.90 <- mhv.90
d2$mhv.00 <- mhv.00
d2$mhv.change <- mhv.change
d2$pct.change <- pct.change
```

## Select Gentrification Variables

Select variables for operationalizing a definition of gentrification:

We need to add some variables from 2000:

Recall we created a 1990 to 2000 variable list for reference:

```{r}
head( vars )
```

```{r}
d2 <- select( d2, 
             
             tractid, cbsa, cbsaname,           # ids / units of analysis
             
             mhv.90, mhv.00, mhv.change, pct.change,    # home value 
             
             hinc90, hu90, own90, rent90,        # ses
             hinc00, hu00, own00, rent00,
             
             empclf90, clf90, unemp90, prof90,   # employment 
             empclf00, clf00, unemp00, prof00,
             
             dpov90, npov90,                     # poverty
             dpov00, npov00,
             
             ag25up90, hs90, col90,              # education 
             ag25up00, hs00, col00,
             
             pop90.1, nhwht90, nhblk90, hisp90, asian90,   # race
             pop00.x, nhwht00, nhblk00, hisp00, asian00
             
          ) # end select


d2 <- 
  d2 %>%
  mutate( 
          # 1990 variables
          p.white.90 = 100 * nhwht90 / pop90.1,
          p.black.90 = 100 * nhblk90 / pop90.1,
          p.hisp.90 = 100 * hisp90 / pop90.1, 
          p.asian.90 = 100 * asian90 / pop90.1,
          p.hs.edu.90 = 100 * (hs90+col90) / ag25up90,
          p.col.edu.90 = 100 * col90 / ag25up90,
          p.prof.90 = 100 * prof90 / empclf90,
          p.unemp.90 = 100 * unemp90 / clf90,
          pov.rate.90 = 100 * npov90 / dpov90,
          
          # 2000 variables
          p.white.00 = 100 * nhwht00 / pop00.x,
          p.black.00 = 100 * nhblk00 / pop00.x,
          p.hisp.00 = 100 * hisp00 / pop00.x, 
          p.asian.00 = 100 * asian00 / pop00.x,
          p.hs.edu.00 = 100 * (hs00+col00) / ag25up00,
          p.col.edu.00 = 100 * col00 / ag25up00,
          p.prof.00 = 100 * prof00 / empclf00,
          p.unemp.00 = 100 * unemp00 / clf00,
          pov.rate.00 = 100 * npov00 / dpov00 )
```

```{r}
d2 <-
  d2 %>%
  group_by( cbsaname ) %>%
  mutate( metro.mhv.pct.90 = ntile( mhv.90, 100 ),
          metro.mhv.pct.00 = ntile( mhv.00, 100 ),
          metro.median.pay.90 = median( hinc90, na.rm=T ),
          metro.median.pay.00 = median( hinc00, na.rm=T ),
          metro.race.rank.90 = ntile( (100-p.white.90), 100 ) ) %>%
  ungroup() %>%
  mutate( metro.mhv.pct.change = metro.mhv.pct.00 - metro.mhv.pct.90,
          pay.change = metro.median.pay.00 - metro.median.pay.90,
          race.change = p.white.00 - p.white.90,
          mhv.change = mhv.00 - mhv.90 )
```

Descriptive Statistics of Change Variables

```{r}
d3 <-           
  d2 %>%
  select( c( "tractid", "cbsa", "cbsaname",
             "mhv.90", "mhv.00", "mhv.change","pct.change",
          "p.white.90", "p.black.90", "p.hisp.90", "p.asian.90", 
          "p.hs.edu.90", "p.col.edu.90", "p.prof.90",  "p.unemp.90", 
          "pov.rate.90", "p.white.00", "p.black.00", "p.hisp.00", 
          "p.asian.00", "p.hs.edu.00", "p.col.edu.00", "p.prof.00", 
          "p.unemp.00", "pov.rate.00", "metro.mhv.pct.90", 
          "metro.mhv.pct.00", "metro.median.pay.90", "metro.median.pay.00", 
          "metro.mhv.pct.change", "pay.change", "race.change",
          "metro.race.rank.90") ) 
  
# head( d3 ) %>% pander()
```

```{r}
d3 <- data.frame(d3)
stargazer( d3, 
           type=s.type, 
           digits=0, 
           summary.stat = c("min", "p25","median","mean","p75","max") )
```

## Operationalizing Gentrification

Which definition did you select for gentrification, and how would you operationalize it?

```{r}
# income
# percent white
# home values absolute
# home value relative to metro
# education stats ?
# employment stats ?
# income stats ?
# growth of pop per tract (density) ?


# home value in lower than average home in a metro in 1990
poor.1990 <- d3$metro.mhv.pct.90 < 50  

# above average diversity for metro
diverse.1990 <- d3$metro.race.rank.90 > 50 

# home values increased more than overall city gains 
# change in percentile rank within the metro
mhv.pct.increase <- d3$metro.mhv.pct.change > 0

# faster than average growth  
# 25% growth in value is median for the country
home.val.rise <- d3$pct.change > 25 

# proportion of whites increases by more than 3 percent 
# measured by increase in white
loss.diversity <- d3$race.change > 3 

g.flag <- poor.1990 & diverse.1990 & mhv.pct.increase & home.val.rise & loss.diversity

num.candidates <-  sum( poor.1990 & diverse.1990, na.rm=T )
num.gentrified <- sum( g.flag, na.rm=T )

num.gentrified 
```

```{r}
num.candidates

```

```{r}
num.gentrified / num.candidates
```

By this definition only 5.7 percent of urban tracts experience gentrification between 2000 and 2010.

This might skew numbers?

```{r}
# small initial values are skewing percentages
#
# an average home value below $10k is really low -
# these must be mostly vacant lots?

mhv.90[ mhv.90 < 1000 ] <- NA
pct.change <- 100 * ( mhv.change / mhv.90 )
summary( pct.change )
```

## Step 4: Building and Analysing a Neighbohood Dataset


### 4.1: Select Your MSA

```{r}
crosswalk <- read.csv( "https://raw.githubusercontent.com/DS4PS/cpp-529-master/master/data/cbsatocountycrosswalk.csv",  stringsAsFactors=F, colClasses="character" )

# search for citie names by strings for "begins with" 

grep( "^AUS", crosswalk$msaname, value=TRUE ) 

```

### 4.2: Download a Shapefile with Population Data

```{r}
these.msp <- crosswalk$msaname == "AUSTIN-SAN MARCOS, TX"
these.fips <- crosswalk$fipscounty[ these.msp ]
these.fips <- na.omit( these.fips )

state.fips <- substr( these.fips, 1, 2 )
county.fips <- substr( these.fips, 3, 5 )

census_api_key("your-api-key")

aus.pop <-
get_acs( geography = "tract", variables = "B01003_001",
         state = "48", county = county.fips[state.fips=="48"], geometry = TRUE ) %>% 
         select( GEOID, estimate ) %>%
         rename( POP=estimate )
```

### 4.3: Add Census Data

```{r}
URL <- "https://github.com/DS4PS/cpp-529-master/raw/master/data/ltdb_std_2010_sample.rds"
census.dat <- readRDS(gzcon(url( URL )))

# can merge an sf object and data.frame
aus <- merge( aus.pop, census.dat , by.x="GEOID", by.y="tractid" )

# make sure there are no empty polygons
aus <- aus[ ! st_is_empty( aus ) , ]
```

### 4.4: Transform the Shapefile into A Dorling Cartogram

```{r}
aus.sp <- as_Spatial(aus)

class( aus.sp )


```

```{r}
# project map and remove empty tracts
aus.sp <- spTransform( aus.sp, CRS("+init=epsg:3395"))
aus.sp <- aus.sp[ aus.sp$POP != 0 & (! is.na( aus.sp$POP )) , ]

# convert census tract polygons to dorling cartogram
# no idea why k=0.03 works, but it does - default is k=5
aus.sp$pop.w <- aus.sp$POP / 9000 # max(msp.sp$POP)   # standardizes it to max of 1.5
aus_dorling <- cartogram_dorling( x=aus.sp, weight="pop.w", k=0.05 )
plot( aus_dorling )
```
```{r}
tm_shape( aus_dorling ) + 
  tm_polygons( size="POP", col="mhmval12", n=7, style="quantile", palette="Spectral" ) 
```

```{r}

tm_shape( aus_dorling ) + 
  tm_polygons( col="mhmval12", n=10, style="quantile", palette="Spectral" ) +
  tm_layout( "Austin Cartogram", title.position=c("right","top") )
```


# search for citie names by strings, use the ^ anchor for "begins with" 

grep( "^CHI", crosswalk$msaname, value=TRUE ) 


## Part 1 Discussion:

# Question 1: How do changes in home value differ between the 1990-200 period and 2000-2010?

**Answer:** In 2020, there is a very consistant growth in home values from 1990-2000, vs. 2000-2010, where we saw a tapering trend in year to year comparisons. I am sure that this is due to the housing crisis that accompanied the 2008 recession, and caused home values to drop.

# Question 2: What do the authors suggest would predict fall in central city home values between 1990 and 2000?

**Answer:** the author suggests that a decrease in aminity values and nearby labor opportunities would predict a fall in home values, resulting in a loss of population- especially of college-educated, white residents.

## Part 2 Discussion:

# Question 1: Do patterns of neighborhood vitality follow the same patterns as home values? Do we see consistent increases over time? What percentage of tracts improved, according to your measures, and what percentage got worse?

**Answer:** Depends on the the variable that we are looking at. We are likely to see an increase in many (thought to be positive) variables, during a period of "vitality" (i.e. increased college educated population, increased % of professionals, new contruction), although when occuring at a fast rate, this could really mean the 'death' of one community and succession by a new community.

# Question 2: What is the correlation between change in neighborhood health metrics and change in home value? Consider using the pairs() function from the previous lab to describe these relationships.

**Answer:** Increases in home value go hand-in-hand with neighborhood health, when the increase is moderate and allows community members to increase their circumstances simultaneously. In cases were property values grow too fast, and resident community memebers and businesses are not able to transition, there are cases of gentrification. Although, if the community memebership is able to stay in the community and benefit from its increased "value", this is a great indicator of community health.

^ home values + stability = Woohoo!
^ homevalues + volnerability = succession

## Part 3 Discussion:

You were asked to come up with a way to conceptualize gentrification.

This week you will create a new variable in your dataset that allows you to operationalize gentrification and examine its prevelance in the data. 

# Question #1: How many census tracts are candidates (start out at a low income level with high diversity)? And of those how many have transitioned into advanced stages of gentrification? Provide an explanation and justification of the way you measure gentrification in the data.

**Answer:** There were 19,835 cencus tracts that were cadidates for gentrification in 1990. 427 (0.022) tracts transitioned into advanced states of gentrification. As mentioned in my Yellowdig discussion high levels of poverty result in housing instability. that issue occurs when residents of an area of gentrifucation (usually low income and diverse) are not able to find housing in the community any longer and are forced out. As Kriston Capps mentioned in his summary of the study in question, typically black and latinx (and low-income) residents experience high levels of housing discrimination, which could lead to dislocaiton.

## Part 4 Discussion:

### Home Values
Describe the distribution of home values in 2000 - where are high and low-value tracts located in the city/cities?
Compare values in 2000 to changes in values from 2000-2010. Do the largest gains occur in tracts with above or below-average home prices in 2000?

I was unable to get my 2000 data to work with the code, athough, I choose to do this project on Austin,Tx due to my personal knowledge of and relationship with the city.

The largest gains have occured in the tracts with low income housing. Although, the recession did hold gentrification at bay, it caused a large #s of black and hispanic community memebers to move away from city center and towards the east and south. 

### Gentrification
create a map that highlights tracts that are candidates for gentrification in 2000 and tracts that gentify between 2000 and 2010.
Do you find any meaningful patterns in where gentification occurs?

The yellow/orange areas are the ones that would qualify as candidated for gentrification. Those areas colser towards city center are the ones that were gentrified. 

### Community Health
Map your community health indices in 2000.
Map changes in your community health indices between 2000 and 2010.
Do you believe that your indices are stable over time, i.e. that a change in an index value represents an actual improvement in the community? Or are changes more akin to inflation where everyone experiences a nominal rise in wealth but not a real rise?

Community Health would have shown to be helthy in the early years, with increases in HH income and home value. Although as time went on and those areas became more valuable they sky rocketed in value and cause community memebers to move further away from city center.

-------
<br>

Analysis Created By: Ricky Duran
For: CPP 528 - Data Sciences for Public Service III
Created On: "`r format(Sys.time(), '%B %d, %Y')`"

<br>
